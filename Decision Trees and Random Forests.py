# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ygGl15t97kTjVZLB-3ANXTQO3BytgWSY
"""

!pip install pandas numpy opendatasets scikit-learn --quiet

# Commented out IPython magic to ensure Python compatibility.
import opendatasets as od
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
import os
# %matplotlib inline

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 150)
sns.set_style('darkgrid')
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['figure.figsize'] = (10, 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000'

od.download('https://www.kaggle.com/jsphyg/weather-dataset-rattle-package')

os.listdir('weather-dataset-rattle-package')

raw_df = pd.read_csv('weather-dataset-rattle-package/weatherAUS.csv')

raw_df.dropna(subset=['RainTomorrow'], inplace = True)

plt.title('No. of Rows per Year')
sns.countplot(x=pd.to_datetime(raw_df.Date).dt.year);

year = pd.to_datetime(raw_df.Date).dt.year

train_df = raw_df[year < 2015]
val_df = raw_df[year == 2015]
test_df = raw_df[year > 2015]

input_cols = list(train_df.columns)[1:-1]
target_col = 'RainTomorrow'

train_inputs = train_df[input_cols].copy()
train_targets = train_df[target_col].copy()

val_inputs = val_df[input_cols].copy()
val_targets = val_df[target_col].copy()

test_inputs = test_df[input_cols].copy()
test_targets = test_df[target_col].copy()

numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()
categorical_cols = train_inputs.select_dtypes('object').columns.tolist()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean').fit(raw_df[numeric_cols])

train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])
val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])
test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])

test_inputs[numeric_cols].isna().sum()

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler().fit(raw_df[numeric_cols])

train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])
val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])
test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse = False, handle_unknown = 'ignore').fit(train_inputs[categorical_cols])

encoded_cols = list(encoder.get_feature_names_out(categorical_cols))

train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])
val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])
test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])

X_train = train_inputs[numeric_cols + encoded_cols]
X_val = val_inputs[numeric_cols + encoded_cols]
X_test = test_inputs[numeric_cols + encoded_cols]

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(random_state = 42)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model.fit(X_train, train_targets)

train_preds = model.predict(X_train)
train_preds

from sklearn.metrics import accuracy_score, confusion_matrix

pd.value_counts(train_preds)

train_probs = model.predict_proba(X_train)
train_probs

accuracy_score(train_preds,train_targets)

"""The training set accuray is 100% but we can't rely solely on the training set accuracy, we must evaluate the model on the validation set."""

model.score(X_val, val_targets)

val_targets.value_counts() / len(val_targets)

"""It appears that the model has learned the training examples perfect, and doesn't generalize well to previously unseen examples. This phenomenon is called "overfitting", and reducing overfitting is one of the most important parts of any machine learning project."""

from sklearn.tree import plot_tree, export_text

plt.figure(figsize = (80,20))
plot_tree(model, feature_names = X_train.columns, max_depth=2, filled=True)

"""Can you see how the model classifies a given input as a series of decisions? The tree is truncated here, but following any path from the root node down to a leaf will result in "Yes" or "No". Do you see how a decision tree differs from a logistic regression model?


**How a Decision Tree is Created**

Note the `gini` value in each box. This is the loss function used by the decision tree to decide which column should be used for splitting the data, and at what point the column should be split. A lower Gini index indicates a better split. A perfect split (only one class on each side) has a Gini index of 0.

For a mathematical discussion of the Gini Index, watch this video: https://www.youtube.com/watch?v=-W0DnxQK1Eo . It has the following formula:

<img src="https://i.imgur.com/CSC0gAo.png" width="240">

Conceptually speaking, while training the models evaluates all possible splits across all possible columns and picks the best one. Then, it recursively performs an optimal split for the two portions. In practice, however, it's very inefficient to check all possible splits, so the model uses a heuristic (predefined strategy) combined with some randomization.

The iterative approach of the machine learning workflow in the case of a decision tree involves growing the tree layer-by-layer:

<img src="https://i.imgur.com/tlYiXnp.png" width="480">


Let's check the depth of the tree that was created.
"""

tree_text = export_text(model, max_depth=10, feature_names=list(X_train.columns))
print(tree_text[:5000])

"""### Feature Importance

Based on the gini index computations, a decision tree assigns an "importance" value to each feature. These values can be used to interpret the results given by a decision tree.
"""

model.feature_importances_

importance_df = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

importance_df.head(10)

plt.title('Feature Importance')
sns.barplot(data=importance_df.head(10), x='importance', y='feature')

model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, train_targets)

model.score(X_train,train_targets)

model.score(X_val,val_targets)

plt.figure(figsize=(80,20))
plot_tree(model, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_)

print(export_text(model, feature_names=list(X_train.columns)))

def max_depth_error(md):
  model = DecisionTreeClassifier(max_depth=md, random_state= 42)
  model.fit(X_train, train_targets)
  train_error = 1 - model.score(X_train, train_targets)
  val_error = 1 - model.score(X_val, val_targets)
  return {'Max Depth' : md, 'Training Error' : train_error, 'Validation Error' : val_error}

errors_df = pd.DataFrame([max_depth_error(md) for md in range(1,21)])
errors_df

plt.figure()
plt.plot(errors_df['Max Depth'], errors_df['Training Error'])
plt.plot(errors_df['Max Depth'], errors_df['Validation Error'])
plt.title('Training and Validaiton Error')
plt.xticks(range(0,21,2))
plt.xlabel('Max. Depth')
plt.ylabel('Prediction Error (1 - Accuracy)')
plt.legend(['Training', 'Validation'])

model = DecisionTreeClassifier(max_depth=7, random_state=42).fit(X_train, train_targets)
model.score(X_train, train_targets),model.score(X_val, val_targets)

"""**max_leaf_nodes**"""

model = DecisionTreeClassifier(max_leaf_nodes = 128, random_state = 42)

model.fit(X_train, train_targets)
model.score(X_train, train_targets)
model.score(X_val, val_targets)

model.tree_.max_depth

model_text = export_text(model, feature_names=list(X_train.columns))
print(model_text[:3000])

def max_leaf_error(md):
  model = DecisionTreeClassifier(max_leaf_nodes=md, random_state= 42)
  model.fit(X_train, train_targets)
  train_error = 1 - model.score(X_train, train_targets)
  val_error = 1 - model.score(X_val, val_targets)
  return {'Max Leaf' : md, 'Training Error' : train_error, 'Validation Error' : val_error}

# Commented out IPython magic to ensure Python compatibility.
# %%time
# errors_df_leaf = pd.DataFrame([max_leaf_error(md) for md in range(2,128)])

errors_df_leaf

plt.figure()
plt.plot(errors_df_leaf['Max Leaf'], errors_df_leaf['Training Error'])
plt.plot(errors_df_leaf['Max Leaf'], errors_df_leaf['Validation Error'])
plt.title('Training and Validaiton Error')
plt.xticks(range(0,129,12))
plt.xlabel('Max. Depth')
plt.ylabel('Prediction Error (1 - Accuracy)')
plt.legend(['Training', 'Validation'])

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_jobs=-1, random_state=42)

"""`n_jobs` allows the random forest to use mutiple parallel workers to train decision trees, and `random_state=42` ensures that the we get the same results for each execution."""

model.fit(X_train, train_targets)

model.score(X_train, train_targets),model.score(X_val, val_targets)

train_proba = model.predict_proba(X_train)
train_proba

len(model.estimators_)

"""Just like decision tree, random forests also assign an "importance" to each feature, by combining the importance values from individual trees."""

importance_df = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending = False)
importance_df.head(10)

plt.title('Feature Importance')
sns.barplot(data=importance_df.head(10), x='importance', y='feature')

base_model = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_train, train_targets)

base_train_acc = base_model.score(X_train, train_targets)
base_val_acc = base_model.score(X_val, val_targets)

base_accs = base_train_acc, base_val_acc
base_accs

model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=10)

model.fit(X_train, train_targets)

model.score(X_train, train_targets), model.score(X_val, val_targets)

base_accs

model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=500)
model.fit(X_train, train_targets)

model.score(X_train, train_targets) , model.score(X_val, val_targets)

base_accs

